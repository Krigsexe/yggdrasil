/**
 * Groq Adapter
 *
 * Adapter for Groq API (OpenAI-compatible).
 * Used by NORNES (qwen-qwq-32b), SAGA (llama-3.3-70b), and LOKI (qwen3-32b).
 *
 * Available Models (Dec 2025):
 * - qwen-qwq-32b: Math (79.5% AIME 2024), Logic (66.4 BFCL)
 * - qwen/qwen3-32b: Advanced reasoning and critical analysis
 * - qwen-2.5-coder-32b: Specialized coding
 * - llama-3.3-70b-versatile: General knowledge (131K context)
 * - llama-3.1-8b-instant: Fast general tasks
 *
 * @see https://console.groq.com/docs/models
 */

import { Injectable } from '@nestjs/common';
import { CouncilMember, createLogger } from '@yggdrasil/shared';
import { ILLMAdapter, CouncilMemberResponse, COUNCIL_SYSTEM_PROMPTS } from './llm.adapter.js';

const logger = createLogger('GroqAdapter', 'info');

interface GroqMessage {
  role: 'system' | 'user' | 'assistant';
  content: string;
}

interface GroqResponse {
  id: string;
  choices: Array<{
    message: { role: string; content: string };
    finish_reason: string;
  }>;
  model: string;
  usage: {
    prompt_tokens: number;
    completion_tokens: number;
    total_tokens: number;
  };
}

export interface GroqAdapterConfig {
  member: CouncilMember;
  defaultModel: string;
  modelEnvVar?: string;
  maxTokens?: number;
  temperature?: number;
}

/**
 * Groq Models Configuration
 * Optimized selection based on benchmarks
 */
export const GROQ_MODELS = {
  // Math & Logic - Best for NORNES
  QWEN_QWQ_32B: 'qwen-qwq-32b',

  // Critical Analysis - Best for LOKI
  QWEN3_32B: 'qwen/qwen3-32b',

  // Coding - Specialized
  QWEN_2_5_CODER_32B: 'qwen-2.5-coder-32b',

  // General Knowledge - Best for SAGA
  LLAMA_3_3_70B_VERSATILE: 'llama-3.3-70b-versatile',

  // Fast responses
  LLAMA_3_1_8B_INSTANT: 'llama-3.1-8b-instant',
} as const;

@Injectable()
export class GroqAdapter implements ILLMAdapter {
  readonly member: CouncilMember;
  readonly modelId: string;
  private readonly apiKey: string | undefined;
  private readonly baseUrl = 'https://api.groq.com/openai/v1';
  private readonly maxTokens: number;
  private readonly temperature: number;

  constructor(config: GroqAdapterConfig) {
    this.member = config.member;
    this.apiKey = process.env.GROQ_API_KEY;
    this.modelId = config.modelEnvVar
      ? (process.env[config.modelEnvVar] ?? config.defaultModel)
      : config.defaultModel;
    this.maxTokens = config.maxTokens ?? 4096;
    this.temperature = config.temperature ?? 0.7;
  }

  isAvailable(): boolean {
    return !!this.apiKey;
  }

  async query(prompt: string): Promise<CouncilMemberResponse> {
    if (!this.isAvailable()) {
      logger.warn(`${this.member} Groq API key not configured, using placeholder`);
      return this.placeholderResponse(prompt);
    }

    try {
      const messages: GroqMessage[] = [
        { role: 'system', content: COUNCIL_SYSTEM_PROMPTS[this.member] },
        { role: 'user', content: prompt },
      ];

      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${this.apiKey}`,
        },
        body: JSON.stringify({
          model: this.modelId,
          max_tokens: this.maxTokens,
          temperature: this.temperature,
          messages,
        }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Groq API error: ${response.status} - ${errorText}`);
      }

      const data = (await response.json()) as GroqResponse;
      const content = data.choices[0]?.message.content ?? '';

      logger.info(`${this.member} Groq response received`, {
        model: data.model,
        promptTokens: data.usage.prompt_tokens,
        completionTokens: data.usage.completion_tokens,
      });

      return {
        content,
        confidence: this.estimateConfidence(content),
        reasoning: `Response generated by ${data.model} via Groq`,
        model: data.model,
      };
    } catch (error) {
      logger.error(`${this.member} Groq API call failed`, error as Error);
      return this.placeholderResponse(prompt);
    }
  }

  private placeholderResponse(prompt: string): CouncilMemberResponse {
    return {
      content: `[${this.member} placeholder] Query: "${prompt.slice(0, 50)}..."`,
      confidence: 50,
      reasoning: `Placeholder - ${this.member} Groq API not available`,
    };
  }

  private estimateConfidence(content: string): number {
    const uncertainWords = ['might', 'maybe', 'possibly', 'uncertain', 'unclear', 'perhaps'];
    const confidentWords = [
      'definitely',
      'certainly',
      'clearly',
      'verified',
      'proven',
      'confirmed',
    ];

    const lowerContent = content.toLowerCase();
    let confidence = 70;

    for (const word of uncertainWords) {
      if (lowerContent.includes(word)) confidence -= 5;
    }
    for (const word of confidentWords) {
      if (lowerContent.includes(word)) confidence += 5;
    }

    return Math.max(30, Math.min(95, confidence));
  }
}

/**
 * NORNES Adapter - Math & Logic Specialist
 * Uses Qwen QWQ-32B for superior mathematical reasoning
 * Benchmarks: 79.5% AIME 2024, 66.4% BFCL
 */
@Injectable()
export class NornesGroqAdapter extends GroqAdapter {
  constructor() {
    super({
      member: CouncilMember.NORNES,
      defaultModel: GROQ_MODELS.QWEN_QWQ_32B,
      modelEnvVar: 'GROQ_NORNES_MODEL',
      temperature: 0.3, // Lower for precise math
    });
  }
}

/**
 * SAGA Adapter - Knowledge Specialist
 * Uses Llama 3.3 70B for broad general knowledge
 * Features: 131K context window
 */
@Injectable()
export class SagaGroqAdapter extends GroqAdapter {
  constructor() {
    super({
      member: CouncilMember.SAGA,
      defaultModel: GROQ_MODELS.LLAMA_3_3_70B_VERSATILE,
      modelEnvVar: 'GROQ_SAGA_MODEL',
      temperature: 0.6,
    });
  }
}

/**
 * LOKI Adapter - Critical Challenger
 * Uses Qwen3-32B for rigorous critical analysis
 * Features: Advanced reasoning, creative challenges
 */
@Injectable()
export class LokiGroqAdapter extends GroqAdapter {
  constructor() {
    super({
      member: CouncilMember.LOKI,
      defaultModel: GROQ_MODELS.QWEN3_32B,
      modelEnvVar: 'GROQ_LOKI_MODEL',
      temperature: 0.8, // Higher for creative challenges
    });
  }

  /**
   * Challenge a council member's response
   * LOKI's special ability to critically analyze responses
   */
  async challenge(response: CouncilMemberResponse): Promise<{
    challenge: string;
    severity: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL';
  } | null> {
    const challengePrompt = `As LOKI, the critical challenger of the YGGDRASIL council, analyze and challenge this response:

Response to challenge:
"${response.content}"

Original confidence: ${response.confidence}%
Reasoning provided: ${response.reasoning || 'None'}

Your task:
1. Identify logical flaws, unsupported claims, or gaps in reasoning
2. Challenge assumptions that may be incorrect
3. Point out potential risks or overlooked considerations
4. Rate the severity of issues found

Respond with a critical challenge and severity rating (LOW/MEDIUM/HIGH/CRITICAL).
If the response is sound, say "No significant issues found" with severity "LOW".`;

    try {
      const result = await this.query(challengePrompt);

      // Parse severity from response
      const contentUpper = result.content.toUpperCase();
      let severity: 'LOW' | 'MEDIUM' | 'HIGH' | 'CRITICAL' = 'LOW';

      if (contentUpper.includes('CRITICAL')) severity = 'CRITICAL';
      else if (contentUpper.includes('HIGH')) severity = 'HIGH';
      else if (contentUpper.includes('MEDIUM')) severity = 'MEDIUM';

      // Only return challenge if there are actual issues
      if (result.content.toLowerCase().includes('no significant issues')) {
        return null;
      }

      return {
        challenge: result.content,
        severity,
      };
    } catch (error) {
      logger.error('LOKI challenge failed', error as Error);
      return null;
    }
  }
}
